apiVersion: apps/v1
kind: Deployment
metadata:
  name: prefill
  namespace: llm-inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prefill
  template:
    metadata:
      labels:
        app: prefill
    spec:
      containers:
        - name: prefill
          image: llm-inference/worker:latest
          imagePullPolicy: Never
          command: ["python3", "-m", "workers.prefill"]
          ports:
            - containerPort: 50052
              name: grpc
          env:
            - name: REDIS_HOST
              value: "redis"
          resources:
            requests:
              cpu: "1"
              memory: "4Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "4"
              memory: "8Gi"
              nvidia.com/gpu: "1"
